{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from clasificador import clasificador\n",
    "from worddictionary import worddictionary\n",
    "from textreplace import textreplace\n",
    "from text2tokens import text2tokens\n",
    "\n",
    "from MechanicalSoup import MechanicalSoup\n",
    "from lemma import lemma\n",
    "from worddictionarybabel import worddictionarybabel\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clasificadorobj = clasificador()\n",
    "dictionariopalabras = worddictionary()\n",
    "diccionariobabel = worddictionarybabel()\n",
    "pool = Pool()\n",
    "\n",
    "path = '../ngrams/Spanish/1gms/vocab_cs.wngram'\n",
    "unigrams = clasificadorobj.loadDic(path)\n",
    "totalUnis = sum(unigrams.values())\n",
    "maxValue = max(unigrams.values())\n",
    "\n",
    "path = '../ngrams/Spanish/2gms/2gms.wngram'\n",
    "bigrams = clasificadorobj.loadDic(path)\n",
    "totalBis = sum(bigrams.values())\n",
    "\n",
    "path = '../ngrams/Spanish/3gms/3gms.wngram'\n",
    "trigrams = clasificadorobj.loadDic(path)\n",
    "totalTris = sum(trigrams.values())\n",
    "\n",
    "# DICCIONARIOE2R\n",
    "path = '../E2R/unigram2_non_stop_words.csv'\n",
    "uniE2R = clasificadorobj.loadDic3(path)\n",
    "\n",
    "# Add \"#\" if you  donÂ´t want to train a new model---from here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Acuraccy-Precision-Recall-F1Score\n",
      "0.8110165696372593 0.8462355474509196 0.7267837305044872 0.7497317585168\n",
      "cwihtml\n"
     ]
    }
   ],
   "source": [
    "path = '../spanish/Spanish_Train.tsv'\n",
    "matrix_train = clasificadorobj.getMatrix_train(path, trigrams, totalTris, bigrams, unigrams, totalBis, totalUnis,\n",
    "                                               uniE2R)\n",
    "\n",
    "path = '../spanish/Spanish_Test.tsv'\n",
    "matrix_dev = clasificadorobj.getMatrix_test(path, trigrams, totalTris, bigrams, unigrams, totalBis, totalUnis, uniE2R)\n",
    "\n",
    "numCol = matrix_dev.shape[1]\n",
    "\n",
    "X_train = matrix_train[:, 0:numCol - 1]\n",
    "y_train = matrix_train[:, -1]  # last column\n",
    "\n",
    "numCol = matrix_dev.shape[1]\n",
    "\n",
    "X_dev = matrix_dev[:, 0:numCol - 1]\n",
    "y_dev = matrix_dev[:, -1]  # last column\n",
    "\n",
    "clasificadorobj.SvmClassifier(X_train, y_train)\n",
    "clasificadorobj.SVMLoad() #oly leave this without comment\n",
    "clasificadorobj.SVMEvaluation(y_dev, X_dev)\n",
    "\n",
    "# to here\n",
    "\n",
    "paragraphreplaced = list()\n",
    "\n",
    "dicpares = {}\n",
    "lemmaobj = lemma()\n",
    "Mechanicalsoupobj = MechanicalSoup()\n",
    "\n",
    "# testing the model with this webpage\n",
    "\n",
    "webpage = \"https://www.elmundo.es/papel/2019/07/02/5d15093bfc6c83370a8b467e.html\"\n",
    "\n",
    "if Mechanicalsoupobj.checkingurl(webpage):\n",
    "\n",
    "    paragraph, title = Mechanicalsoupobj.paragraphfromweb(webpage)\n",
    "\n",
    "    if paragraph != '':\n",
    "        x = text2tokens()\n",
    "\n",
    "        words = list()\n",
    "        text = paragraph\n",
    "        sentencelist = x.text2sentence(text)\n",
    "\n",
    "        words = [x.sentence2tokens(sentence) for sentence in sentencelist]\n",
    "\n",
    "        sentenceinparagraph = list()\n",
    "        if words and words[0]:\n",
    "            words = [item for item in words if item]\n",
    "\n",
    "            matrix_deploy = [\n",
    "                clasificadorobj.getMatrix_Deploy(sentencetags, trigrams, totalTris, bigrams, unigrams, totalBis,\n",
    "                                                 totalUnis, uniE2R) for sentencetags in words]\n",
    "# predicting from new text\n",
    "            predictedtags = [clasificadorobj.SVMPredict(rowdeploy) for rowdeploy in matrix_deploy]\n",
    "            sentencevar = None\n",
    "\n",
    "            for j in range(0, len(words)):\n",
    "                sentencetags = words[j]\n",
    "                if sentencetags and sentencetags[0]:\n",
    "                    sentencevar = sentencetags[0][1]\n",
    "\n",
    "                for i in range(0, len(sentencetags)):\n",
    "                    wordreplace = None\n",
    "                    textreplaced = textreplace()\n",
    "                    syn2 = list()\n",
    "                    listindex = 0\n",
    "                    if predictedtags[j][i] == 1:\n",
    "                        dis2 = 0\n",
    "                        synonims = list()\n",
    "                        synonimsb = list()\n",
    "                        finaldic = list()\n",
    "                        #search of posible replacements\n",
    "                        synonimsb = pool.apply_async(diccionariobabel.babelsearch, [sentencetags[i][4]])\n",
    "                        if len(dictionariopalabras.SSinonimos(sentencetags[i][4])):\n",
    "                            if str(sentencetags[i][4][len(sentencetags[i][4]) - 5:]) == 'mente':\n",
    "                                stem = sentencetags[i][4].replace(\"mente\", \"\")\n",
    "                                synonims = pool.apply_async(dictionariopalabras.SSinonimos, [stem])\n",
    "                            else:\n",
    "                                stem = lemmaobj.lemmatize(sentencetags[i][4])\n",
    "                                synonims = pool.apply_async(dictionariopalabras.SSinonimos, [stem])\n",
    "                        if not synonims:\n",
    "                            synonims = pool.apply_async(dictionariopalabras.SSinonimos, [sentencetags[i][4]])\n",
    "                            stem = sentencetags[i][4]\n",
    "                        synonims1 = synonims.get(timeout=10)\n",
    "                        synonimsb2 = synonimsb.get(timeout=10)\n",
    "                        if synonims1 or synonimsb2:\n",
    "                            for h in range(0, len(synonims1)):\n",
    "                                syn2.append(synonims1[h])\n",
    "                            for x in range(0, len(synonimsb2)):\n",
    "                                syn2.append(synonimsb2[x])\n",
    "                            syn2 = set(syn2)\n",
    "                            finaldic = synonims1 + synonimsb2\n",
    "                            dicpares[sentencetags[i][4]] = [syn2]\n",
    "                            dic_synonims = dict.fromkeys(finaldic) \n",
    "                        for candidate in dic_synonims.keys():\n",
    "                            candidatesentencetags = list(sentencetags[i])\n",
    "                            candidatesentencetags[4] = str(candidate)\n",
    "                            candidatelen = len(candidate)\n",
    "                            wordlen = len(sentencetags[i][4])\n",
    "                            candidatesentencetags[3] = candidatesentencetags[2] + candidatelen\n",
    "                            candidatesentencetags[1] = str(candidatesentencetags[1])[\n",
    "                                                       :candidatesentencetags[2]] + str(candidate) + \\\n",
    "                                                       candidatesentencetags[1][\n",
    "                                                       candidatesentencetags[2] + wordlen:]\n",
    "                            # candidatesentencetags[1] = (candidatesentencetags[1][:candidatesentencetags[2]]).encode('utf-8') + str(candidate) + (candidatesentencetags[1][candidatesentencetags[2] + wordlen:]).encode('utf-8')\n",
    "\n",
    "                            listcandidatesentencetags = list()\n",
    "                            listcandidatesentencetags.append(candidatesentencetags)\n",
    "                            # candidatematrix = clasificadorobj.getMatrix_Deploy(listcandidatesentencetags, trigrams, totalTris,bigrams, unigrams, totalBis, totalUnis,uniE2R)\n",
    "                            # candidatepredictedtag = clasificadorobj.SVMPredict(candidatematrix)\n",
    "\n",
    "                            # busqueda de sinonimo optimo en contexto\n",
    "                            dis1 = clasificadorobj.word2vector.similarity(candidate, sentencetags[i][4])\n",
    "                            window = clasificadorobj.getWindow(sentencetags[i][4], sentencetags[i][1],\n",
    "                                                               sentencetags[i][2])\n",
    "                            diswindow1 = clasificadorobj.word2vector.similarity(window[1], candidate)\n",
    "                            diswindow2 = clasificadorobj.word2vector.similarity(window[2], candidate)\n",
    "                            dis3 = dis1 + diswindow1 + diswindow2\n",
    "\n",
    "                            # if dis2 < dis3 and sentencetags[i][4] != candidate.lower() and candidatepredictedtag[0] != 1:\n",
    "                            if dis2 < dis3 and sentencetags[i][4] != candidate.lower():\n",
    "                                synonim = candidate\n",
    "                                dis2 = dis3\n",
    "                                wordreplace = candidatesentencetags[2:5] + sentencetags[i][2:5]\n",
    "                    if wordreplace:\n",
    "                        sentenceinparagraph.append([sentencevar, wordreplace])\n",
    "        paragraph_sentence = [paragraph, sentenceinparagraph]\n",
    "        paragraphreplaced.append(paragraph_sentence)\n",
    "\n",
    "if Mechanicalsoupobj.checkingurl(webpage):\n",
    "    Mechanicalsoupobj.CWItoHTML(paragraphreplaced, paragraph, title)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
